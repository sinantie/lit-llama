lora_path: out/lora/opengpt-single_shot-qa-no-special-toks-preamble/lit-llama-lora-finetuned.pth
pretrained_path: checkpoints/lit-llama/7B/lit-llama.pth
tokenizer_path: checkpoints/lit-llama/tokenizer.model
quantize: null
max_new_tokens: 150
top_k: 200
temperature: 0.8
instruction_tuning: false
special_tokens:
  user: "Human:"
  ai: "AI:"
  eos: "###"
  eod: ""
server_name: 0.0.0.0
share_gradio: false
